{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOZWUJDdBV9D"
   },
   "source": [
    "######AdiPokharna\n",
    "# **Chit 6 or 7 or 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9f0RSeUJLP1"
   },
   "source": [
    "*Problem Statement:*\n",
    "\n",
    "    Implement the Continuous Bag of Words (CBOW) Model for the given (textual document 1) using the below steps:\n",
    "    a. Data preparation\n",
    "    b. Generate training data\n",
    "    c. Train model\n",
    "    d. Output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJO70ku3Ragn"
   },
   "source": [
    "# Importing libraries\n",
    "a. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V51q50EbF-T9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from tensorflow.python.keras import utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyermB1XrW_z"
   },
   "source": [
    "b. Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TIoKhKXrxhj"
   },
   "source": [
    "This will be same for 6, 7, 8 Chits only the data in the file will be different for each chit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4JL9JZ2foO92"
   },
   "outputs": [],
   "source": [
    "# Open a text file in write mode\n",
    "with open('corona.txt', 'w') as file:\n",
    "    # Write the message to the file\n",
    "    file.write(\"\"\"\n",
    "The speed of transmission is an important point of difference between the two viruses.\n",
    "Influenza has a shorter median incubation period (the time from infection to appearance of symptoms)\n",
    "and a shorter serial interval (the time between successive cases) than COVID-19 virus.\n",
    "The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days.\n",
    "This means that influenza can spread faster than COVID-19.\n",
    "\n",
    "Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –\n",
    "transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza.\n",
    "In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset,\n",
    "at present, this does not appear to be a major driver of transmission.\n",
    "\n",
    "The reproductive number – the number of secondary infections generated from one infected individual –\n",
    "is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza.\n",
    "However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HslLN21ffhSK"
   },
   "outputs": [],
   "source": [
    "data=open('corona.txt','r')\n",
    "corona_data = [text for text in data if text.count(' ') >= 2]\n",
    "vectorize = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJiL6QSRfzO3"
   },
   "source": [
    "## Fit data to tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wBUwYdBJElVz"
   },
   "outputs": [],
   "source": [
    "vectorize.fit_on_texts(corona_data)\n",
    "corona_data = vectorize.texts_to_sequences(corona_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8bCcicjif4i8"
   },
   "outputs": [],
   "source": [
    "# Find total no of words and total no of sentences.\n",
    "total_vocab = sum(len(s) for s in corona_data)\n",
    "word_count = len(vectorize.word_index) + 1\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDDnSgoprn34"
   },
   "source": [
    "c. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "akOXPLfBgE8p"
   },
   "outputs": [],
   "source": [
    "# Generate the pairs of Context words and target words\n",
    "def cbow_model(data, window_size, total_vocab):\n",
    "    total_length = window_size*2\n",
    "    for text in data:\n",
    "        text_len = len(text)\n",
    "        for idx, word in enumerate(text):\n",
    "            context_word = []\n",
    "            target   = []\n",
    "            begin = idx - window_size\n",
    "            end = idx + window_size + 1\n",
    "            context_word.append([text[i] for i in range(begin, end) if 0 <= i < text_len and i != idx])\n",
    "            target.append(word)\n",
    "            contextual = sequence.pad_sequences(context_word, total_length=total_length)\n",
    "            final_target = utils.to_categorical(target, total_vocab)\n",
    "            yield(contextual, final_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvCwshtogInC"
   },
   "source": [
    "Create Neural Network model with following parameters :\n",
    "\n",
    "    Model type : sequential\n",
    "    \n",
    "    Layers : Dense , Lambda , embedding. Compile\n",
    "\n",
    "    Options : (loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AJOQ_RBgH0R",
    "outputId": "ff5a866d-d0d6-4caf-dab0-9a36311ba82f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_vocab, output_dim=100, input_length=window_size*2))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(100,)))\n",
    "model.add(Dense(total_vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "for i in range(10):\n",
    "    cost = 0\n",
    "    for x, y in cbow_model(data, window_size, total_vocab):\n",
    "        cost += model.train_on_batch(contextual, final_target)\n",
    "    print(i, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ub-YzNuvgHwr",
    "outputId": "78353680-e34b-46f6-b388-dbda2d3fdfa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vector file of some word for testing\n",
    "dimensions=100\n",
    "vect_file = open('/content/vectors.txt' ,'w')\n",
    "vect_file.write('{} {}\\n'.format(total_vocab,dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4U-4kh1Ygb_f"
   },
   "outputs": [],
   "source": [
    "# Assign weights to your trained model\n",
    "weights = model.get_weights()[0]\n",
    "for text, i in vectorize.word_index.items():\n",
    "    final_vec = ' '.join(map(str, list(weights[i, :])))\n",
    "    vect_file.write('{} {}\\n'.format(text, final_vec))\n",
    "vect_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yulzRM7Lrqyg"
   },
   "source": [
    "d. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Pte5kYhAgb8O"
   },
   "outputs": [],
   "source": [
    "# Use the vectors created in Gemsim\n",
    "cbow_output = gensim.models.KeyedVectors.load_word2vec_format('/content/vectors.txt', binary = False, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keSXc08Lgb5f",
    "outputId": "cfaf164c-0ea0-478c-abe6-16c1a5daa132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('24', 0.2239864021539688),\n",
       " ('major', 0.21599477529525757),\n",
       " ('covid', 0.20103251934051514),\n",
       " ('period', 0.18392768502235413),\n",
       " ('faster', 0.15826314687728882),\n",
       " ('symptomatic', 0.15524835884571075),\n",
       " ('viruses', 0.15504062175750732),\n",
       " ('comparisons', 0.146196648478508),\n",
       " ('number', 0.1459341198205948),\n",
       " ('3', 0.14284861087799072)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the word to get similar type of words\n",
    "cbow_output.most_similar(positive=['virus'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
